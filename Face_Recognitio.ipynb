{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Lambda ,Dense ,Flatten , Dropout , GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "3LvtJGU7lC4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_folder = \"/content/drive/MyDrive/DATA/data/\"\n",
        "def save_data(raw_folder=raw_folder):\n",
        "\n",
        "    dest_size = (128, 128)\n",
        "    print(\"Bắt đầu xử lý ảnh...\")\n",
        "\n",
        "    pixels = []\n",
        "    labels = []\n",
        "\n",
        "    # Lặp qua các folder con trong thư mục raw\n",
        "    for folder in listdir(raw_folder):\n",
        "        if folder!='.DS_Store':\n",
        "            print(\"Folder=\",folder)\n",
        "            # Lặp qua các file trong từng thư mục chứa các em\n",
        "            for file in listdir(raw_folder  + folder):\n",
        "                if file!='.DS_Store':\n",
        "                    print(\"File=\", file)\n",
        "                    pixels.append( cv2.resize(cv2.imread(raw_folder  + folder +\"/\" + file),dsize=(128,128)))\n",
        "                    labels.append( folder)\n",
        "\n",
        "    pixels = np.array(pixels)\n",
        "    labels = np.array(labels)#.reshape(-1,1)\n",
        "\n",
        "    from sklearn.preprocessing import LabelBinarizer\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "    print(labels)\n",
        "\n",
        "    file = open('pix.data', 'wb')\n",
        "    # dump information to that file\n",
        "    pickle.dump((pixels,labels), file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    return\n",
        "\n",
        "def load_data():\n",
        "    file = open('pix.data', 'rb')\n",
        "\n",
        "    # dump information to that file\n",
        "    (pixels, labels) = pickle.load(file)\n",
        "\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    print(pixels.shape)\n",
        "    print(labels.shape)\n",
        "\n",
        "\n",
        "    return pixels, labels"
      ],
      "metadata": {
        "id": "4QLwwcRilYQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_data()\n",
        "X,y = load_data()\n",
        "#random.shuffle(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Q_bk3VIJmO4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vgg 16 model\n",
        "classifier_vgg16 = VGG16(input_shape= (64,64,3),include_top=False,weights='imagenet')"
      ],
      "metadata": {
        "id": "8MExCkMLmiY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Không train phần top layers\n",
        "for layer in classifier_vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "If_F-v08mwop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding extra layers for our class/images\n",
        "main_model = classifier_vgg16.output\n",
        "main_model = GlobalAveragePooling2D()(main_model)\n",
        "main_model = Dense(1024,activation='relu')(main_model)\n",
        "main_model = Dense(1024,activation='relu')(main_model)\n",
        "main_model = Dense(512,activation='relu')(main_model)\n",
        "main_model = Dropout(0.5)(main_model)\n",
        "main_model = Dense(4,activation='softmax')(main_model)"
      ],
      "metadata": {
        "id": "jpWCZ1MwnOk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling\n",
        "model = Model(inputs = classifier_vgg16.input , outputs = main_model)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1LTIxRKNm8XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nQLFTx-AobpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.1,\n",
        "    rescale=1./255,\n",
        "\twidth_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "\thorizontal_flip=True,\n",
        "    brightness_range=[0.2,1.5], fill_mode=\"nearest\")\n",
        "\n",
        "aug_val = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "5Y2vTgbWpQqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(aug.flow(X_train, y_train, batch_size=64),\n",
        "                               epochs=50,# steps_per_epoch=len(X_train)//64,\n",
        "                               validation_data=aug.flow(X_test,y_test,\n",
        "                               batch_size=64),\n",
        "                               callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "gak2T9bflC0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "DjpewNZKhSm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    axs[0].plot(range(1, len(model_history.history[acc]) + 1), model_history.history[acc])\n",
        "    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1), model_history.history[val_acc])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1), len(model_history.history[acc]) / 10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
        "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']) / 10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "    plt.savefig('roc.png')"
      ],
      "metadata": {
        "id": "zt1NtMs0lCx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_history(history)"
      ],
      "metadata": {
        "id": "-smVN0aUlCuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name =[\"Duong\", \"Duyen\", \"Hung\", \"Lan\"]\n",
        "image_org = cv2.imread('/content/drive/MyDrive/DATA/data/MinhDuong/993.png')\n",
        "image = cv2.resize(image_org, dsize=(64, 64))\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "predict = model.predict(image)\n",
        "\n",
        "print(\"This picture is: \", class_name[np.argmax(predict[0])], predict[0])\n",
        "if (np.max(predict)>=0.8):\n",
        "    # Show image\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    org = (50, 50)\n",
        "    fontScale = 1.5\n",
        "    color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "\n",
        "    cv2.putText(image_org, class_name[np.argmax(predict)], org, font,\n",
        "                fontScale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "plt.imshow(image_org)\n",
        "#plt.imshow(\"Picture\", image)"
      ],
      "metadata": {
        "id": "kogFtMQGkBPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Face_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}